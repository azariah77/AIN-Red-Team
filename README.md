Python script to generate encoded, jailbreak, and context-manipulation prompts for AIN testing (simulation only).
This generator creates high-risk prompts for research. Run detection and policy checks before sending anything to a live LLM. Always have authorization and ethical review.
